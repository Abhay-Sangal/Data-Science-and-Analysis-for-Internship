# -*- coding: utf-8 -*-
"""Innobyte Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YBYml2lPOnt6iNdbpwG46eFTqxhnzgQ9
"""

# Import necessary libraries
import pandas as pd
import numpy as np

# Load the dataset
file_path = "/content/Amazon Sale Report.csv"  # Replace with the path to your file
df = pd.read_csv(file_path)

# Inspect the dataset
print("First 5 rows of the dataset:")
print(df.head())

print("\nDataset Information:")
print(df.info())

print("\nChecking for missing values:")
print(df.isnull().sum())

print("\nChecking for duplicates:")
print(df.duplicated().sum())

# --- Data Cleaning ---

# Handling missing values
# Replace missing values in numerical columns with 0 or mean
numerical_columns = ['Amount', 'Quantity']  # Adjust based on your dataset
for col in numerical_columns:
    if col in df.columns:
        df[col].fillna(0, inplace=True)

# Replace missing values in categorical columns with "Unknown"
categorical_columns = ['Product Category', 'Size', 'Order Status', 'Fulfillment Method', 'Sales Channel']  # Adjust based on your dataset
for col in categorical_columns:
    if col in df.columns:
        df[col].fillna('Unknown', inplace=True)

# Standardizing date formats
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')  # Convert to datetime format
    print("\nDate column after standardization:")
    print(df['Date'].head())

# Standardizing text columns (e.g., trimming whitespace and converting to lowercase)
text_columns = ['Product Category', 'Order Status', 'Fulfillment Method', 'Sales Channel']  # Adjust as necessary
for col in text_columns:
    if col in df.columns:
        df[col] = df[col].str.strip().str.lower()

# Converting numerical columns to appropriate types
if 'Amount' in df.columns:
    df['Amount'] = pd.to_numeric(df['Amount'], errors='coerce')
if 'Quantity' in df.columns:
    df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce')

# --- Enhancing the Dataset ---

# Extract Year, Month, Week, and Day from the Date column
if 'Date' in df.columns:
    df['Year'] = df['Date'].dt.year
    df['Month'] = df['Date'].dt.month
    df['Week'] = df['Date'].dt.isocalendar().week
    df['Day'] = df['Date'].dt.day

# Categorize Order Status into active (delivered, shipped) vs inactive (cancelled, returned)
if 'Order Status' in df.columns:
    df['Order Category'] = df['Order Status'].apply(
        lambda x: 'active' if x in ['delivered', 'shipped'] else 'inactive'
    )

# --- Final Inspection ---
print("\nCleaned Dataset Information:")
print(df.info())

print("\nSample Rows of the Enhanced Dataset:")
print(df.head())

# --- Save the Cleaned Dataset ---
output_path = "Cleaned_Amazon_Sale_Report.csv"
df.to_csv(output_path, index=False)
print(f"\nCleaned dataset saved to {output_path}")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the cleaned dataset
file_path = "/content/Cleaned_Amazon_Sale_Report.csv"  # Replace with your cleaned dataset file path
df = pd.read_csv(file_path)

# Ensure Date is in datetime format
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])

# Aggregate monthly sales
monthly_sales = df.groupby(df['Date'].dt.to_period('M'))['Amount'].sum().reset_index()
monthly_sales['Date'] = monthly_sales['Date'].dt.to_timestamp()  # Convert period to timestamp

# Aggregate weekly sales
weekly_sales = df.groupby(df['Date'].dt.to_period('W'))['Amount'].sum().reset_index()
weekly_sales['Date'] = weekly_sales['Date'].dt.to_timestamp()

# Aggregate daily sales
daily_sales = df.groupby(df['Date'].dt.date)['Amount'].sum().reset_index()
daily_sales.rename(columns={'Date': 'Day', 'Amount': 'Daily Revenue'}, inplace=True)

print("Monthly Sales Data:")
print(monthly_sales.head())

# Total Revenue
total_revenue = df['Amount'].sum()
print(f"Total Revenue: {total_revenue}")

# Average Order Value (AOV)
aov = df['Amount'].mean()
print(f"Average Order Value (AOV): {aov}")

# Month-over-Month Growth Rate (MoM)
monthly_sales['MoM Growth Rate (%)'] = monthly_sales['Amount'].pct_change() * 100

# Year-over-Year Growth Rate (YoY)
if 'Year' in df.columns:
    yearly_sales = df.groupby('Year')['Amount'].sum().reset_index()
    yearly_sales['YoY Growth Rate (%)'] = yearly_sales['Amount'].pct_change() * 100
    print("\nYearly Sales Data with YoY Growth Rate:")
    print(yearly_sales)

# Line chart for monthly sales trends
plt.figure(figsize=(12, 6))
sns.lineplot(data=monthly_sales, x='Date', y='Amount', marker='o', label='Monthly Sales')
plt.title('Monthly Sales Trends', fontsize=14)
plt.xlabel('Month')
plt.ylabel('Revenue')
plt.grid()
plt.legend()
plt.show()

# Bar chart for monthly sales
plt.figure(figsize=(12, 6))
sns.barplot(data=monthly_sales, x=monthly_sales['Date'].dt.strftime('%b %Y'), y='Amount', palette='viridis')
plt.xticks(rotation=45)
plt.title('Monthly Sales Comparison', fontsize=14)
plt.xlabel('Month-Year')
plt.ylabel('Revenue')
plt.grid(axis='y')
plt.show()

peak_month = monthly_sales[monthly_sales['Amount'] == monthly_sales['Amount'].max()]
print(f"\nPeak Sales Period:\n{peak_month}")

# Weekly sales trends visualization
plt.figure(figsize=(12, 6))
sns.lineplot(data=weekly_sales, x='Date', y='Amount', marker='o', label='Weekly Sales')
plt.title('Weekly Sales Trends', fontsize=14)
plt.xlabel('Week')
plt.ylabel('Revenue')
plt.grid()
plt.legend()
plt.show()

# Cumulative Sales over time (line chart)
df['Cumulative Sales'] = df['Amount'].cumsum()

plt.figure(figsize=(12, 6))
sns.lineplot(data=df, x='Date', y='Cumulative Sales', marker='o', label='Cumulative Sales')
plt.title('Cumulative Sales Over Time', fontsize=14)
plt.xlabel('Date')
plt.ylabel('Cumulative Revenue')
plt.grid(True)
plt.legend()
plt.show()

# Annual sales visualization
yearly_sales = df.groupby('Year')['Amount'].sum().reset_index()

plt.figure(figsize=(10, 6))
sns.barplot(data=yearly_sales, x='Year', y='Amount', palette='Blues_d')
plt.title('Annual Sales Comparison', fontsize=14)
plt.xlabel('Year')
plt.ylabel('Total Revenue')
plt.grid(axis='y')
plt.show()

# Sorting by highest revenue months
top_months = monthly_sales.sort_values('Amount', ascending=False).head(10)

plt.figure(figsize=(12, 6))
sns.barplot(data=top_months, x=top_months['Date'].dt.strftime('%b %Y'), y='Amount', palette='magma')
plt.xticks(rotation=45)
plt.title('Top 10 Months by Revenue', fontsize=14)
plt.xlabel('Month-Year')
plt.ylabel('Revenue')
plt.show()

# Sales by Product Category
category_sales = df.groupby('Category')['Amount'].sum().reset_index()

plt.figure(figsize=(12, 6))
sns.barplot(data=category_sales, x='Category', y='Amount', palette='Set2')
plt.title('Sales by Product Category', fontsize=14)
plt.xlabel('Product Category')
plt.ylabel('Revenue')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()

# Grouping by Product Category to analyze sales and quantities
category_sales = df.groupby('Category').agg(
    total_revenue=('Amount', 'sum'),
    total_quantity=('Qty', 'sum')
).reset_index()

# Sort categories by total revenue for better readability
category_sales = category_sales.sort_values(by='total_revenue', ascending=False)

# Display the top categories by total revenue
print(category_sales.head())

# Calculate the contribution of each category to total revenue
total_revenue = df['Amount'].sum()
category_sales['revenue_contribution'] = (category_sales['total_revenue'] / total_revenue) * 100

# Display the categories with their revenue contribution percentage
print(category_sales[['Category', 'revenue_contribution']].head())

# Group by Product Category and Size to analyze quantity sold by size
size_sales = df.groupby(['Category', 'Size']).agg(
    total_quantity=('Qty', 'sum')
).reset_index()

# Sort by quantity sold
size_sales = size_sales.sort_values(by='total_quantity', ascending=False)

# Display top 10 sizes with the most sales
print(size_sales.head(10))

# Group by Product Name to get total sales and quantities sold
product_sales = df.groupby('Category').agg(
    total_revenue=('Amount', 'sum'),
    total_quantity=('Qty', 'sum')
).reset_index()

# Sort by total revenue to get top-performing products
top_performing_products = product_sales.sort_values(by='total_revenue', ascending=False)

# Display the top 10 products by revenue
print(top_performing_products.head(10))

# Pie chart to visualize revenue distribution by product category
plt.figure(figsize=(8, 8))
plt.pie(category_sales['total_revenue'], labels=category_sales['Category'], autopct='%1.1f%%', startangle=90, colors=sns.color_palette('Set3', len(category_sales)))
plt.title('Product Category Revenue Distribution', fontsize=14)
plt.show()

# Bar plot for top categories by total revenue
plt.figure(figsize=(12, 6))
sns.barplot(data=category_sales.head(10), x='Category', y='total_revenue', palette='viridis')
plt.title('Top Categories by Revenue', fontsize=14)
plt.xlabel('Product Category')
plt.ylabel('Total Revenue')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()

# Pivot the size_sales data for heatmap visualization
size_sales_pivot = size_sales.pivot(index='Category', columns='Size', values='total_quantity').fillna(0)

# Heatmap visualization
plt.figure(figsize=(14, 8))
sns.heatmap(size_sales_pivot, annot=True, cmap='Blues', fmt='.0f', cbar_kws={'label': 'Quantity Sold'})
plt.title('Product Size vs Quantity Sold Heatmap', fontsize=14)
plt.xlabel('Size')
plt.ylabel('Product Category')
plt.show()

# Categorize Order Status into successful (Delivered/ Shipped) and unsuccessful (Cancelled/ Returned)
df['Order Status Category'] = df['Status'].apply(
    lambda x: 'Successful' if x in ['Delivered', 'Shipped'] else 'Unsuccessful'
)

# Group by Fulfillment Method and Order Status Category
fulfillment_order_status = df.groupby(['Fulfilment', 'Order Status Category']).size().unstack().reset_index()

# Calculate success rate (successful orders / total orders)
fulfillment_order_status['Success Rate'] = (fulfillment_order_status['Successful'] /
                                             (fulfillment_order_status['Successful'] + fulfillment_order_status['Unsuccessful'])) * 100

# Display the success rate by Fulfillment Method
print(fulfillment_order_status[['Fulfilment', 'Success Rate']])

# Stacked bar chart for order status by Fulfillment Method
fulfillment_order_status.set_index('Fulfilment')[['Successful', 'Unsuccessful']].plot(kind='bar', stacked=True, figsize=(10, 6), color=['#1f77b4', '#ff7f0e'])

plt.title('Order Status Split by Fulfilment', fontsize=14)
plt.xlabel('Fulfilment')
plt.ylabel('Number of Orders')
plt.xticks(rotation=45)
plt.legend(title='Order Status', labels=['Successful', 'Unsuccessful'])
plt.show()

# Bar plot for success rate by Fulfillment Method
plt.figure(figsize=(10, 6))
sns.barplot(data=fulfillment_order_status, x='Fulfilment', y='Success Rate', palette='coolwarm')

plt.title('Success Rate by Fulfilment', fontsize=14)
plt.xlabel('Fulfilment')
plt.ylabel('Success Rate (%)')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()

# Ensure 'Order Date' is in datetime format
df['Date'] = pd.to_datetime(df['Date'], errors='coerce')

# Calculate the most recent order date in the dataset
reference_date = df['Date'].max()

# Calculate Recency, Frequency, and Monetary for each Shipping City (proxy for customers)
rfm_df = df.groupby('ship-city').agg(
    Recency=('Date', lambda x: (reference_date - x.max()).days),
    Frequency=('Order ID', 'count'),
    Monetary=('Amount', 'sum')
).reset_index()

# Display the RFM DataFrame
print(rfm_df.head())

# Rank the data manually based on the Recency, Frequency, and Monetary values
rfm_df['Recency_Rank'] = pd.cut(rfm_df['Recency'], 3, labels=['High', 'Medium', 'Low'])
rfm_df['Frequency_Rank'] = pd.cut(rfm_df['Frequency'], 3, labels=['Low', 'Medium', 'High'])
rfm_df['Monetary_Rank'] = pd.cut(rfm_df['Monetary'], 3, labels=['Low', 'Medium', 'High'])

# Combine the ranks to create the RFM score
rfm_df['RFM_Score'] = rfm_df['Recency_Rank'].astype(str) + rfm_df['Frequency_Rank'].astype(str) + rfm_df['Monetary_Rank'].astype(str)

# Display the segmented data
print(rfm_df[['Recency', 'Frequency', 'Monetary', 'Recency_Rank', 'Frequency_Rank', 'Monetary_Rank', 'RFM_Score']].head())

# Visualize the distribution of customers across RFM segments
plt.figure(figsize=(10, 6))
sns.countplot(x='RFM_Score', data=rfm_df, palette='viridis')
plt.title('Distribution of Shipping Cities Across RFM Segments', fontsize=14)
plt.xlabel('RFM Score')
plt.ylabel('Number of Shipping Cities')
plt.xticks(rotation=45)
plt.show()

# Create a pivot table for the heatmap
rfm_heatmap_data = rfm_df.pivot_table(values='ship-city',
                                      index='Recency_Rank',
                                      columns='Frequency_Rank',
                                      aggfunc='count').fillna(0)

# Plot the heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(rfm_heatmap_data, annot=True, fmt='d', cmap='coolwarm', cbar=False)
plt.title('Heatmap of Recency vs Frequency Segments', fontsize=14)
plt.xlabel('Frequency Rank')
plt.ylabel('Recency Rank')
plt.show()

# Group by Location (Shipping City)
location_sales = df.groupby('ship-city').agg(
    Total_Sales=('Amount', 'sum'),
    Total_Orders=('Order ID', 'count')
).reset_index()

# Sort by Total Sales to identify high-value customer clusters
location_sales_sorted = location_sales.sort_values(by='Total_Sales', ascending=False)

# Display the top customer clusters by location
print(location_sales_sorted.head())

# Bar plot for total sales by location (Shipping City)
plt.figure(figsize=(12, 6))
sns.barplot(x='ship-city', y='Total_Sales', data=location_sales_sorted, palette='Blues_d')
plt.title('High-Value Customer Clusters by Location', fontsize=14)
plt.xlabel('Shipping City')
plt.ylabel('Total Sales')
plt.xticks(rotation=45)
plt.show()

# Check for available location columns
df[['ship-state', 'ship-city']].head()

# Aggregate total sales by State and City
state_sales = df.groupby('ship-state').agg(
    Total_Sales=('Amount', 'sum'),
    Total_Orders=('Order ID', 'count')
).reset_index()

city_sales = df.groupby('ship-city').agg(
    Total_Sales=('Amount', 'sum'),
    Total_Orders=('Order ID', 'count')
).reset_index()

# Display the top states and cities based on total sales
print(state_sales.sort_values(by='Total_Sales', ascending=False).head())
print(city_sales.sort_values(by='Total_Sales', ascending=False).head())

# Install GeoPandas
!pip install geopandas

# Install Folium for interactive maps
!pip install folium

# Install Plotly for interactive plots
!pip install plotly

import matplotlib.pyplot as plt
import seaborn as sns

# Aggregate sales data by state
state_sales = df.groupby('ship-state').agg(
    Total_Sales=('Amount', 'sum'),
    Total_Orders=('Order ID', 'count')
).reset_index()

# Sort states by total sales
state_sales_sorted = state_sales.sort_values(by='Total_Sales', ascending=False)

# Plot a bar chart of total sales by state
plt.figure(figsize=(10, 6))
sns.barplot(x='ship-state', y='Total_Sales', data=state_sales_sorted)
plt.xticks(rotation=90)
plt.title('Total Sales by State')
plt.xlabel('State')
plt.ylabel('Total Sales (₹)')
plt.show()

# Aggregate sales data by city
city_sales = df.groupby('ship-city').agg(
    Total_Sales=('Amount', 'sum'),
    Total_Orders=('Order ID', 'count')
).reset_index()

# Sort cities by total sales
city_sales_sorted = city_sales.sort_values(by='Total_Sales', ascending=False)

# Plot a bar chart of total sales by city
plt.figure(figsize=(10, 6))
sns.barplot(x='ship-city', y='Total_Sales', data=city_sales_sorted)
plt.xticks(rotation=90)
plt.title('Total Sales by City')
plt.xlabel('City')
plt.ylabel('Total Sales (₹)')
plt.show()

# Scatter plot of sales vs. order count by state
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Total_Orders', y='Total_Sales', data=state_sales_sorted, hue='ship-state', palette='tab20')
plt.title('Sales vs. Order Count by State')
plt.xlabel('Total Orders')
plt.ylabel('Total Sales (₹)')
plt.legend(title='State', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

# Focus on the top 10 high-contribution states and cities
top_states = state_sales_sorted.head(10)
top_cities = city_sales_sorted.head(10)

# Display top states and cities
print("Top 10 States by Sales:")
print(top_states)

print("Top 10 Cities by Sales:")
print(top_cities)

# Identify regions with low sales for growth potential (underserved areas)
underserved_states = state_sales_sorted.tail(10)
underserved_cities = city_sales_sorted.tail(10)

print("Underserved States (Low Sales):")
print(underserved_states)

print("Underserved Cities (Low Sales):")
print(underserved_cities)